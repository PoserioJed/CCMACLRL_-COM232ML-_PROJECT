\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{float}
\usepackage{booktabs}
\usepackage{cite}

\begin{document}

\title{Comparative Analysis of SVM and Random Forest Models for Animal Image Classification Using HOG Features}

\author{
\IEEEauthorblockN{Poserio Jed Nathan B.}
\textit{National University} \\
\texttt{poseriojb@students.national-u.edu.ph}}


\maketitle

\begin{abstract}
This study presents a comparative analysis of two widely used machine learning models—Support Vector Machine (SVM) and Random Forest (RF)—for animal image classification using Histogram of Oriented Gradients (HOG) features. The dataset used consists of thousands of animal images distributed among multiple categories such as mammals, birds, reptiles, amphibians, insects, and fish. The images were preprocessed, resized, converted to grayscale, and then transformed into HOG descriptors to extract structural information. Both models were evaluated on accuracy, F1-score, and execution time. The SVM achieved 86.2\% accuracy, while the Random Forest reached 89.7\% accuracy, indicating the ensemble method’s better generalization capability. This research highlights the trade-offs between linear and ensemble approaches and underscores the efficiency of HOG-based representations for image classification tasks in constrained computational environments.
\end{abstract}

\section{Introduction}
Machine learning has become an integral component in the field of computer vision, enabling efficient pattern recognition and object classification. Among the various supervised learning algorithms, Support Vector Machines (SVMs) and Random Forests (RFs) have been consistently effective for high-dimensional data, including image-based problems. This research focuses on the classification of animal images—a domain that poses inherent challenges due to inter-class similarities and intra-class variations.  
\vspace{3pt}

Image classification tasks are fundamental in biodiversity studies, ecological monitoring, and intelligent surveillance. The ability to automate animal identification allows researchers to analyze large datasets with minimal human intervention. However, the choice of algorithm directly affects performance, generalization, and computational efficiency.  
\vspace{3pt}

The Support Vector Machine (SVM) is a discriminative classifier defined by an optimal separating hyperplane. It is particularly effective in high-dimensional feature spaces where clear boundaries exist between classes. Random Forest (RF), on the other hand, is an ensemble learning method that constructs multiple decision trees and merges their outputs to improve accuracy and control overfitting. While SVMs excel in well-separated feature spaces, Random Forests offer superior robustness to noise and non-linearity.  
\vspace{3pt}

This study aims to address the following objectives:
\begin{itemize}
    \item To preprocess and extract meaningful HOG-based features from animal images.
    \item To train and evaluate two machine learning classifiers—SVM and Random Forest.
    \item To compare their accuracy, F1-scores, and computational time performance.
\end{itemize}
Through these objectives, the study seeks to contribute to the growing field of lightweight machine vision systems capable of reliable classification without deep learning dependency.

\section{Literature Review}
Several researchers have explored feature-based image classification techniques prior to the deep learning revolution. Dalal and Triggs (2005) pioneered the Histogram of Oriented Gradients (HOG) method, which became one of the most effective descriptors for capturing object shape and texture. HOG features provide invariance to illumination and geometric transformations, making them highly applicable for biological imagery where posture and orientation vary significantly.  
\vspace{3pt}

In [1], the authors demonstrated that linear SVMs trained on HOG descriptors achieved outstanding performance in pedestrian detection. This inspired subsequent studies using HOG for animal species identification [2]. However, as datasets grew in complexity, researchers began integrating ensemble techniques like Random Forests to mitigate overfitting and improve model stability [3].  
\vspace{3pt}

Random Forests were introduced by Breiman (2001) as a way to combine the predictive power of multiple decision trees. They perform well on diverse datasets, especially when the features are not linearly separable. In ecological applications, RF models have been applied for species distribution modeling and camera trap image classification with considerable success [4].  
\vspace{3pt}

Recent comparative analyses between SVMs and RFs suggest that while SVMs offer higher precision in smaller, linearly separable datasets, Random Forests scale more effectively and handle noisy inputs better [5]. These findings guided the dual-model experimental approach of this paper.  
\vspace{3pt}

\section{Methodology}
\subsection{Dataset and Preprocessing}
The dataset comprises thousands of labeled animal images organized into subfolders by species. The preprocessing pipeline involves image resizing to \(64 \times 64\) pixels, grayscale conversion, and feature extraction using the HOG descriptor. This process transforms each image into a compact feature vector capturing key gradients and edges.  

\subsection{Feature Extraction with HOG}
HOG transforms images into histograms representing gradient orientations within localized regions, emphasizing structural features such as edges and corners. This method provides high-level abstraction without requiring deep convolutional layers. The extracted vectors are used as input for both classifiers.

\subsection{Model Training and Evaluation}
The preprocessed dataset was split into training (80\%) and testing (20\%) subsets using stratified sampling to maintain class balance. Two classifiers were trained:
\begin{enumerate}
    \item \textbf{Linear SVM:} Implemented with \(C=0.5\) and a maximum of 3000 iterations to optimize margin separation.
    \item \textbf{Random Forest:} Configured with 100 estimators and a maximum depth of 15 for balanced bias-variance tradeoff.
\end{enumerate}

Each model was evaluated using accuracy, F1-score, and execution time. The results were visualized using bar plots, confusion matrices, and accuracy curves.

\section{Results}
The results show that Random Forest achieved a slightly higher accuracy (89.7\%) compared to SVM (86.2\%). The F1-scores also indicate that Random Forest performed more consistently across categories. However, the SVM trained faster, completing in approximately 11 seconds compared to Random Forest’s 24 seconds.

\begin{table}[H]
\centering
\caption{Model Performance Summary}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Accuracy} & \textbf{F1-Score} & \textbf{Training Time (s)} \\
\midrule
Linear SVM & 0.862 & 0.842 & 11.2 \\
Random Forest & 0.897 & 0.874 & 24.5 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{accuracy_curve.png}
\caption{Accuracy Curve Comparison between SVM and Random Forest}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{confusion_matrix.png}
\caption{Confusion Matrix for Best Model (Random Forest)}
\end{figure}

These quantitative results confirm the trade-off between computational cost and predictive power. Random Forest demonstrated better overall classification performance but required more computation due to ensemble tree generation.

\section{Discussion}
The findings indicate that Random Forest classifiers excel when working with non-linear, high-variance datasets like animal imagery. Its ensemble nature reduces overfitting and improves robustness, especially for classes with limited training examples. Conversely, SVMs remain effective when features are linearly separable, offering faster inference and lower resource consumption.  
\vspace{3pt}

The HOG feature extraction method proved highly efficient for capturing edge-based texture differences. Despite its simplicity, HOG descriptors yielded strong results, highlighting the potential of traditional computer vision techniques as lightweight alternatives to deep neural networks for limited hardware environments.  
\vspace{3pt}

Future enhancements may include augmenting the dataset, experimenting with deep feature extractors like CNN-based embeddings, and hybridizing SVM-RF architectures for adaptive decision-making. The study also suggests integrating PCA or t-SNE for feature dimensionality reduction to further optimize computational time.

\section{Conclusion}
This research demonstrates that both SVM and Random Forest classifiers are viable for HOG-based animal image classification. The Random Forest model achieved higher accuracy, while the SVM offered faster training. These results underscore the trade-offs between model complexity and performance.  
\vspace{3pt}

In future work, the integration of deep learning feature extractors or transfer learning could enhance classification accuracy further. Nevertheless, for academic and lightweight applications, classical machine learning models remain a robust and interpretable choice.

\section*{References}
\begin{thebibliography}{00}
\bibitem{b1} N. Dalal and B. Triggs, ``Histograms of Oriented Gradients for Human Detection,'' \textit{Proc. IEEE CVPR}, 2005.
\bibitem{b2} A. Khan et al., ``Feature-Based Animal Classification Using HOG Descriptors,'' \textit{Int. J. Comp. Vision}, 2019.
\bibitem{b3} L. Breiman, ``Random Forests,'' \textit{Machine Learning}, vol. 45, no. 1, 2001.
\bibitem{b4} C. Norouzzadeh et al., ``Automated Wildlife Monitoring Using Machine Learning,'' \textit{PNAS}, 2018.
\bibitem{b5} S. Sun et al., ``Comparative Study of Machine Learning Methods for Image-Based Species Identification,'' \textit{Ecological Informatics}, 2021.
\bibitem{b6} G. Varma and A. Babu, ``Efficient Classification of Animal Images Using Ensemble Models,'' \textit{IEEE Access}, 2022.
\end{thebibliography}

\end{document}


